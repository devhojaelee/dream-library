#!/usr/bin/env python3
"""
ì±… ë©”íƒ€ë°ì´í„° ë³´ì™„ ìŠ¤í¬ë¦½íŠ¸

Z-Libraryì—ì„œ ê°€ì ¸ì˜¤ì§€ ëª»í•œ ì±… í‘œì§€ì™€ ì„¤ëª…ì„ Google Books APIë¥¼ í†µí•´ ë³´ì™„í•©ë‹ˆë‹¤.
"""

import os
import json
import requests
import time
import re
from pathlib import Path
from typing import Optional, Dict, Tuple
from io import BytesIO
from PIL import Image
from difflib import SequenceMatcher
from datetime import datetime

# ê²½ë¡œ ì„¤ì •
BOOKS_DIR = Path("books")
METADATA_DIR = BOOKS_DIR / "metadata"
COVERS_DIR = BOOKS_DIR / "covers"

# Google Books API ì„¤ì •
GOOGLE_BOOKS_API = "https://www.googleapis.com/books/v1/volumes"

# í•´ìƒë„ ì„ê³„ê°’ (ì´ë³´ë‹¤ ì‘ìœ¼ë©´ ì„œì ì—ì„œ ë” ì¢‹ì€ ì´ë¯¸ì§€ ê²€ìƒ‰)
MIN_COVER_WIDTH = 200

# ì œëª© ìœ ì‚¬ë„ ì„ê³„ê°’ (ì´ë³´ë‹¤ ë‚®ìœ¼ë©´ ë‹¤ë¥¸ ì±…ìœ¼ë¡œ íŒë‹¨)
MIN_TITLE_SIMILARITY = 0.6

class MetadataEnricher:
    def __init__(self):
        self.updated_count = 0
        self.failed_count = 0
        self.skipped_count = 0

    def clean_title(self, title: str) -> str:
        """ì œëª© ì •ì œ: ê´„í˜¸, ëŒ€ê´„í˜¸ ë‚´ìš© ì œê±° (ìˆ«ìëŠ” ìœ ì§€)"""
        # (ê°œì •íŒ) ì œê±°
        cleaned = re.sub(r'\([^)]*\)', '', title)

        # [íœ´ê³ ìƒ ìˆ˜ìƒì‘] ì œê±°
        cleaned = re.sub(r'\[[^\]]*\]', '', cleaned)

        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        cleaned = re.sub(r'\s+', ' ', cleaned)

        return cleaned.strip()

    def calculate_title_similarity(self, title1: str, title2: str) -> float:
        """ë‘ ì œëª©ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        # ì†Œë¬¸ì ë³€í™˜ ë° ê³µë°± ì •ê·œí™”
        t1 = re.sub(r'\s+', ' ', title1.lower().strip())
        t2 = re.sub(r'\s+', ' ', title2.lower().strip())

        # SequenceMatcherë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
        return SequenceMatcher(None, t1, t2).ratio()

    def search_google_books_single(self, query: str, original_title: str) -> Optional[Dict]:
        """Google Books APIë¡œ ë‹¨ì¼ ì¿¼ë¦¬ ê²€ìƒ‰ (ì œëª© ìœ ì‚¬ë„ ê²€ì¦ í¬í•¨)"""
        try:
            params = {
                'q': query,
                'maxResults': 5,
                'langRestrict': 'ko'  # í•œêµ­ì–´ ìš°ì„ 
            }

            response = requests.get(GOOGLE_BOOKS_API, params=params, timeout=10)

            if response.status_code == 200:
                data = response.json()

                if 'items' in data and len(data['items']) > 0:
                    best_match = None
                    best_score = 0

                    for item in data['items']:
                        volume_info = item.get('volumeInfo', {})

                        # ì œëª© ìœ ì‚¬ë„ ê²€ì¦
                        result_title = volume_info.get('title', '')
                        similarity = self.calculate_title_similarity(original_title, result_title)

                        # ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ìŠ¤í‚µ
                        if similarity < MIN_TITLE_SIMILARITY:
                            continue

                        # ì™„ì „ì„± ì ìˆ˜ ê³„ì‚°
                        completeness_score = 0
                        if volume_info.get('description'):
                            completeness_score += 2
                        if volume_info.get('imageLinks'):
                            completeness_score += 2
                        if volume_info.get('authors'):
                            completeness_score += 1
                        if volume_info.get('publishedDate'):
                            completeness_score += 1

                        # ì¢…í•© ì ìˆ˜ = ì™„ì „ì„± + ìœ ì‚¬ë„ ë³´ë„ˆìŠ¤
                        total_score = completeness_score + (similarity * 3)

                        if total_score > best_score:
                            best_score = total_score
                            best_match = item

                    return best_match

            return None

        except Exception as e:
            print(f"  âš ï¸  Google Books API ì˜¤ë¥˜: {e}")
            return None

    def search_google_books(self, title: str, author: str = None) -> Optional[Dict]:
        """ì ì§„ì  ê²€ìƒ‰ ì „ëµìœ¼ë¡œ ì±… ì •ë³´ ê²€ìƒ‰"""
        print(f"  ğŸ” ê²€ìƒ‰ ì „ëµ ì‹œì‘...")

        # ì •ì œëœ ì œëª© ì¤€ë¹„
        cleaned_title = self.clean_title(title)

        # ê²€ìƒ‰ ì‹œë„ ìˆœì„œ
        search_attempts = []

        # 1ì°¨: ì›ë³¸ ì œëª© + ì €ì
        if author:
            query = f"{title} {author}"
            search_attempts.append(("ì›ë³¸+ì €ì", query))

        # 2ì°¨: ì •ì œëœ ì œëª© + ì €ì (ì›ë³¸ê³¼ ë‹¤ë¥¼ ë•Œë§Œ)
        if author and cleaned_title != title:
            query = f"{cleaned_title} {author}"
            search_attempts.append(("ì •ì œ+ì €ì", query))

        # 3ì°¨: ì •ì œëœ ì œëª©ë§Œ
        if cleaned_title != title:
            search_attempts.append(("ì •ì œ", cleaned_title))

        # 4ì°¨: ì›ë³¸ ì œëª©ë§Œ
        search_attempts.append(("ì›ë³¸", title))

        # ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
        for attempt_name, query in search_attempts:
            print(f"  ğŸ“– [{attempt_name}] '{query}' ê²€ìƒ‰ ì¤‘...")
            result = self.search_google_books_single(query, title)

            if result:
                volume_info = result.get('volumeInfo', {})
                result_title = volume_info.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ')
                similarity = self.calculate_title_similarity(title, result_title)
                print(f"  âœ… ë°œê²¬! '{result_title}' (ìœ ì‚¬ë„: {similarity:.2f})")
                return result
            else:
                print(f"  âŒ ê²°ê³¼ ì—†ìŒ")

        return None

    def download_cover_image(self, image_url: str, filename: str) -> Optional[str]:
        """í‘œì§€ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ê°€ì¥ í° ìœ íš¨í•œ ì´ë¯¸ì§€ ì„ íƒ, ì˜¬ë°”ë¥¸ í™•ì¥ì ì‚¬ìš©)"""
        try:
            # HTTPë¥¼ HTTPSë¡œ ë³€ê²½ (Google BooksëŠ” HTTPS ì§€ì›)
            if image_url.startswith('http://'):
                image_url = image_url.replace('http://', 'https://')

            # ëª¨ë“  zoom ë ˆë²¨ ì‹œë„í•˜ê³  ê°€ì¥ í° ì´ë¯¸ì§€ ì„ íƒ
            best_image = None
            best_size = 0
            best_zoom = None

            for zoom_level in [1, 2, 3]:
                try_url = image_url.replace('zoom=1', f'zoom={zoom_level}')

                response = requests.get(try_url, timeout=10)

                if response.status_code == 200 and len(response.content) > 1000:
                    # 1KB ì´ìƒì˜ ì´ë¯¸ì§€ë§Œ ìœ íš¨í•˜ë‹¤ê³  íŒë‹¨
                    size = len(response.content)
                    if size > best_size:
                        best_size = size
                        best_image = response.content
                        best_zoom = zoom_level

            if best_image:
                # ì´ë¯¸ì§€ í˜•ì‹ ê°ì§€ (magic number í™•ì¸)
                if best_image[:8].startswith(b'\x89PNG'):
                    ext = '.png'
                elif best_image[:3].startswith(b'\xff\xd8\xff'):
                    ext = '.jpg'
                else:
                    ext = '.jpg'  # ê¸°ë³¸ê°’

                cover_filename = f"{filename.replace('.epub', '')}{ext}"
                cover_path = COVERS_DIR / cover_filename

                with open(cover_path, 'wb') as f:
                    f.write(best_image)

                print(f"  ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {best_size // 1024}KB (zoom={best_zoom}, {ext[1:].upper()})")
                return cover_filename
            else:
                print(f"  âš ï¸  ìœ íš¨í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None

        except Exception as e:
            print(f"  âš ï¸  í‘œì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None

    def get_image_dimensions(self, image_data: bytes) -> Tuple[int, int]:
        """ì´ë¯¸ì§€ ë°ì´í„°ì—ì„œ ê°€ë¡œxì„¸ë¡œ í¬ê¸° ì¶”ì¶œ"""
        try:
            img = Image.open(BytesIO(image_data))
            return img.size  # (width, height)
        except Exception as e:
            print(f"  âš ï¸  ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ ì˜¤ë¥˜: {e}")
            return (0, 0)

    def search_naver_books(self, title: str, author: str = None) -> Optional[str]:
        """ë„¤ì´ë²„ ì±… ê²€ìƒ‰ì—ì„œ í‘œì§€ ì´ë¯¸ì§€ URL ê²€ìƒ‰"""
        try:
            # ë„¤ì´ë²„ ì±… ê²€ìƒ‰ (í¬ë¡¤ë§)
            from bs4 import BeautifulSoup

            search_query = f"{title} {author}" if author else title
            response = requests.get(
                'https://search.naver.com/search.naver',
                params={'where': 'book', 'sm': 'tab_jum', 'query': search_query},
                timeout=10,
                headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'}
            )

            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                # ì²« ë²ˆì§¸ ì±… í‘œì§€ ì´ë¯¸ì§€ ì°¾ê¸° (ì—…ë°ì´íŠ¸ëœ ì„ íƒì)
                img = soup.select_one('img.thumb')
                if img:
                    img_url = img.get('src') or img.get('data-src')
                    if img_url and img_url.startswith('http'):
                        # ê³ í•´ìƒë„ ë²„ì „ìœ¼ë¡œ ë³€ê²½ (type=w216 â†’ type=w600)
                        if 'type=w216' in img_url:
                            img_url = img_url.replace('type=w216', 'type=w600')
                        return img_url

            return None
        except Exception as e:
            print(f"  âš ï¸  ë„¤ì´ë²„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None


    def upgrade_low_resolution_cover(self, title: str, author: str, current_cover_path: Path) -> bool:
        """í•´ìƒë„ê°€ ë‚®ì€ í‘œì§€ë¥¼ í•œêµ­ ì„œì ì—ì„œ ë” ì¢‹ì€ ì´ë¯¸ì§€ë¡œ êµì²´"""
        try:
            # í˜„ì¬ ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
            with open(current_cover_path, 'rb') as f:
                current_data = f.read()

            width, height = self.get_image_dimensions(current_data)

            if width >= MIN_COVER_WIDTH:
                return False  # í•´ìƒë„ê°€ ì¶©ë¶„í•¨

            print(f"  ğŸ” í•´ìƒë„ê°€ ë‚®ìŒ ({width}x{height}), ë” ì¢‹ì€ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")

            # ë„¤ì´ë²„ ì±… ê²€ìƒ‰ì—ì„œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì°¾ê¸°
            bookstore_sources = [
                ('ë„¤ì´ë²„', self.search_naver_books),
            ]

            for store_name, search_func in bookstore_sources:
                img_url = search_func(title, author)

                if img_url:
                    # URL ìŠ¤í‚´ ìˆ˜ì • (//ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° https: ì¶”ê°€)
                    if img_url.startswith('//'):
                        img_url = 'https:' + img_url

                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    img_response = requests.get(img_url, timeout=10)

                    if img_response.status_code == 200 and len(img_response.content) > 1000:
                        new_width, new_height = self.get_image_dimensions(img_response.content)

                        # ë” í° ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
                        if new_width > width:
                            # íŒŒì¼ í˜•ì‹ ê°ì§€
                            if img_response.content[:8].startswith(b'\x89PNG'):
                                ext = '.png'
                            elif img_response.content[:3].startswith(b'\xff\xd8\xff'):
                                ext = '.jpg'
                            else:
                                ext = '.jpg'

                            # ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
                            current_cover_path.unlink()

                            # ìƒˆ íŒŒì¼ ì €ì¥
                            new_path = current_cover_path.parent / f"{title}{ext}"
                            with open(new_path, 'wb') as f:
                                f.write(img_response.content)

                            print(f"  âœ¨ {store_name}ì—ì„œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ: {new_width}x{new_height} ({len(img_response.content) // 1024}KB)")
                            return True

            print(f"  âš ï¸  ë” ì¢‹ì€ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í•¨")
            return False

        except Exception as e:
            print(f"  âš ï¸  ì´ë¯¸ì§€ ì—…ê·¸ë ˆì´ë“œ ì˜¤ë¥˜: {e}")
            return False

    def enrich_metadata(self, epub_filename: str) -> bool:
        """ë‹¨ì¼ ì±…ì˜ ë©”íƒ€ë°ì´í„° ë³´ì™„"""
        title = epub_filename.replace('.epub', '')
        metadata_path = METADATA_DIR / f"{title}.json"

        # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ì½ê¸°
        metadata = {}
        if metadata_path.exists():
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

        # ì´ë¯¸ ì‹œë„í–ˆìœ¼ë©´ ìŠ¤í‚µ
        if metadata.get('enrichment_attempted'):
            print(f"â­ï¸  {title[:50]}... - ì´ë¯¸ ë³´ì™„ ì‹œë„í•¨")
            self.skipped_count += 1
            return False

        # ì´ë¯¸ ì™„ì „í•œ ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ (ì‹¤ì œ íŒŒì¼ ì¡´ì¬ í™•ì¸)
        has_description = metadata.get('description') is not None

        cover_filename = metadata.get('cover')
        has_cover = False
        if cover_filename:
            cover_path = COVERS_DIR / cover_filename
            has_cover = cover_path.exists()  # ì‹¤ì œ íŒŒì¼ ì¡´ì¬ í™•ì¸

        if has_cover and has_description:
            print(f"â­ï¸  {title[:50]}... - ì´ë¯¸ ì™„ì „í•œ ë©”íƒ€ë°ì´í„° ì¡´ì¬")
            metadata['enrichment_attempted'] = True
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            self.skipped_count += 1
            return False

        print(f"ğŸ” {title[:50]}...")

        # ì €ì ì •ë³´ ì¶”ì¶œ (ìˆìœ¼ë©´ ê²€ìƒ‰ì— í™œìš©)
        author = metadata.get('author')

        # Google Booksì—ì„œ ê²€ìƒ‰
        book_info = self.search_google_books(title, author)

        if not book_info:
            print(f"  âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            # ì‹¤íŒ¨í•´ë„ í”Œë˜ê·¸ ì €ì¥ (ì¬ì‹œë„ ë°©ì§€)
            metadata['enrichment_attempted'] = True
            METADATA_DIR.mkdir(parents=True, exist_ok=True)
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            self.failed_count += 1
            return False

        volume_info = book_info.get('volumeInfo', {})
        updated = False

        # ì„¤ëª… ë³´ì™„
        if not has_description and 'description' in volume_info:
            description = volume_info['description']
            metadata['description'] = description
            print(f"  âœ… ì„¤ëª… ì¶”ê°€: {description[:50]}...")
            updated = True

        # í‘œì§€ ë³´ì™„
        if not has_cover and 'imageLinks' in volume_info:
            image_links = volume_info['imageLinks']
            # thumbnail ë˜ëŠ” smallThumbnail ì‚¬ìš©
            image_url = image_links.get('thumbnail') or image_links.get('smallThumbnail')

            if image_url:
                cover_filename = self.download_cover_image(image_url, epub_filename)

                if cover_filename:
                    metadata['cover'] = cover_filename
                    print(f"  âœ… í‘œì§€ ë‹¤ìš´ë¡œë“œ: {cover_filename}")
                    updated = True

                    # í•´ìƒë„ ì²´í¬ ë° ì—…ê·¸ë ˆì´ë“œ
                    cover_path = COVERS_DIR / cover_filename
                    author = metadata.get('author', '')
                    if self.upgrade_low_resolution_cover(title, author, cover_path):
                        # íŒŒì¼ëª…ì´ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                        new_cover_filename = None
                        for ext in ['.jpg', '.png']:
                            possible_path = COVERS_DIR / f"{title}{ext}"
                            if possible_path.exists():
                                new_cover_filename = f"{title}{ext}"
                                break
                        if new_cover_filename and new_cover_filename != cover_filename:
                            metadata['cover'] = new_cover_filename

        # ê¸°íƒ€ ë©”íƒ€ë°ì´í„° ë³´ì™„
        if 'authors' in volume_info and not metadata.get('author'):
            metadata['author'] = ', '.join(volume_info['authors'])
            print(f"  âœ… ì €ì ì¶”ê°€: {metadata['author']}")
            updated = True

        if 'publishedDate' in volume_info and not metadata.get('year'):
            # YYYY-MM-DD í˜•ì‹ì—ì„œ ì—°ë„ë§Œ ì¶”ì¶œ
            year = volume_info['publishedDate'].split('-')[0]
            metadata['year'] = year
            print(f"  âœ… ì¶œíŒë…„ë„ ì¶”ê°€: {year}")
            updated = True

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        # ì‹œë„í–ˆìŒì„ í‘œì‹œ (ì„±ê³µ/ì‹¤íŒ¨ ë¬´ê´€)
        metadata['enrichment_attempted'] = True

        if updated:
            METADATA_DIR.mkdir(parents=True, exist_ok=True)

            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

            self.updated_count += 1
            print(f"  ğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            return True
        else:
            print(f"  âš ï¸  ë³´ì™„í•  ì •ë³´ ì—†ìŒ")
            # ì—…ë°ì´íŠ¸ ì—†ì–´ë„ í”Œë˜ê·¸ëŠ” ì €ì¥
            METADATA_DIR.mkdir(parents=True, exist_ok=True)
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            self.failed_count += 1
            return False

    def run(self):
        """ëª¨ë“  EPUB íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° ë³´ì™„"""
        start_time = datetime.now()
        print("\n" + "=" * 60)
        print("ğŸ“š Dream Library ë©”íƒ€ë°ì´í„° ë³´ì™„ ì‹œì‘")
        print(f"ğŸ• ì‹¤í–‰ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S %Z')}")
        print("=" * 60)

        # covers ë””ë ‰í† ë¦¬ ìƒì„±
        COVERS_DIR.mkdir(parents=True, exist_ok=True)

        # EPUB íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        epub_files = list(BOOKS_DIR.glob("*.epub"))

        if not epub_files:
            print("âŒ EPUB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\nì´ {len(epub_files)}ê°œì˜ ì±…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n")

        for i, epub_path in enumerate(epub_files, 1):
            print(f"\n[{i}/{len(epub_files)}] ", end="")
            self.enrich_metadata(epub_path.name)

            # API í˜¸ì¶œ ì œí•œ ê³ ë ¤ (1ì´ˆ ëŒ€ê¸°)
            if i < len(epub_files):
                time.sleep(1)

        # ê²°ê³¼ ìš”ì•½
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        print("\n" + "=" * 60)
        print("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼")
        print("=" * 60)
        print(f"ğŸ• ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ• ì¢…ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ")
        print(f"âœ… ì—…ë°ì´íŠ¸ë¨: {self.updated_count}ê°œ")
        print(f"â­ï¸  ìŠ¤í‚µë¨: {self.skipped_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {self.failed_count}ê°œ")
        print("=" * 60)

if __name__ == "__main__":
    enricher = MetadataEnricher()
    enricher.run()
