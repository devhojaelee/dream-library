#!/usr/bin/env python3
"""
ì±… ë©”íƒ€ë°ì´í„° ë³´ì™„ ìŠ¤í¬ë¦½íŠ¸

Z-Libraryì—ì„œ ê°€ì ¸ì˜¤ì§€ ëª»í•œ ì±… í‘œì§€ì™€ ì„¤ëª…ì„ Google Books APIë¥¼ í†µí•´ ë³´ì™„í•©ë‹ˆë‹¤.
"""

import os
import json
import requests
import time
from pathlib import Path
from typing import Optional, Dict, Tuple
from io import BytesIO
from PIL import Image

# ê²½ë¡œ ì„¤ì •
BOOKS_DIR = Path("books")
METADATA_DIR = BOOKS_DIR / "metadata"
COVERS_DIR = BOOKS_DIR / "covers"

# Google Books API ì„¤ì •
GOOGLE_BOOKS_API = "https://www.googleapis.com/books/v1/volumes"

# í•´ìƒë„ ì„ê³„ê°’ (ì´ë³´ë‹¤ ì‘ìœ¼ë©´ ì„œì ì—ì„œ ë” ì¢‹ì€ ì´ë¯¸ì§€ ê²€ìƒ‰)
MIN_COVER_WIDTH = 200

class MetadataEnricher:
    def __init__(self):
        self.updated_count = 0
        self.failed_count = 0
        self.skipped_count = 0

    def search_google_books(self, title: str) -> Optional[Dict]:
        """Google Books APIë¡œ ì±… ì •ë³´ ê²€ìƒ‰ (ì—¬ëŸ¬ ê²°ê³¼ ì¤‘ ê°€ì¥ ì™„ì „í•œ ì •ë³´ ì„ íƒ)"""
        try:
            # ì œëª©ìœ¼ë¡œ ê²€ìƒ‰ (ìµœëŒ€ 5ê°œ ê²°ê³¼)
            params = {
                'q': title,
                'maxResults': 5,
                'langRestrict': 'ko'  # í•œêµ­ì–´ ìš°ì„ 
            }

            response = requests.get(GOOGLE_BOOKS_API, params=params, timeout=10)

            if response.status_code == 200:
                data = response.json()

                if 'items' in data and len(data['items']) > 0:
                    # ì—¬ëŸ¬ ê²°ê³¼ ì¤‘ ê°€ì¥ ì™„ì „í•œ ì •ë³´ë¥¼ ê°€ì§„ ì±… ì„ íƒ
                    best_match = None
                    best_score = 0

                    for item in data['items']:
                        volume_info = item.get('volumeInfo', {})
                        score = 0

                        # ì„¤ëª…ì´ ìˆìœ¼ë©´ +2ì 
                        if volume_info.get('description'):
                            score += 2

                        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ +2ì 
                        if volume_info.get('imageLinks'):
                            score += 2

                        # ì €ìê°€ ìˆìœ¼ë©´ +1ì 
                        if volume_info.get('authors'):
                            score += 1

                        # ì¶œíŒì¼ì´ ìˆìœ¼ë©´ +1ì 
                        if volume_info.get('publishedDate'):
                            score += 1

                        if score > best_score:
                            best_score = score
                            best_match = item

                    return best_match

            return None

        except Exception as e:
            print(f"  âš ï¸  Google Books API ì˜¤ë¥˜: {e}")
            return None

    def download_cover_image(self, image_url: str, filename: str) -> Optional[str]:
        """í‘œì§€ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ê°€ì¥ í° ìœ íš¨í•œ ì´ë¯¸ì§€ ì„ íƒ, ì˜¬ë°”ë¥¸ í™•ì¥ì ì‚¬ìš©)"""
        try:
            # HTTPë¥¼ HTTPSë¡œ ë³€ê²½ (Google BooksëŠ” HTTPS ì§€ì›)
            if image_url.startswith('http://'):
                image_url = image_url.replace('http://', 'https://')

            # ëª¨ë“  zoom ë ˆë²¨ ì‹œë„í•˜ê³  ê°€ì¥ í° ì´ë¯¸ì§€ ì„ íƒ
            best_image = None
            best_size = 0
            best_zoom = None

            for zoom_level in [1, 2, 3]:
                try_url = image_url.replace('zoom=1', f'zoom={zoom_level}')

                response = requests.get(try_url, timeout=10)

                if response.status_code == 200 and len(response.content) > 1000:
                    # 1KB ì´ìƒì˜ ì´ë¯¸ì§€ë§Œ ìœ íš¨í•˜ë‹¤ê³  íŒë‹¨
                    size = len(response.content)
                    if size > best_size:
                        best_size = size
                        best_image = response.content
                        best_zoom = zoom_level

            if best_image:
                # ì´ë¯¸ì§€ í˜•ì‹ ê°ì§€ (magic number í™•ì¸)
                if best_image[:8].startswith(b'\x89PNG'):
                    ext = '.png'
                elif best_image[:3].startswith(b'\xff\xd8\xff'):
                    ext = '.jpg'
                else:
                    ext = '.jpg'  # ê¸°ë³¸ê°’

                cover_filename = f"{filename.replace('.epub', '')}{ext}"
                cover_path = COVERS_DIR / cover_filename

                with open(cover_path, 'wb') as f:
                    f.write(best_image)

                print(f"  ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {best_size // 1024}KB (zoom={best_zoom}, {ext[1:].upper()})")
                return cover_filename
            else:
                print(f"  âš ï¸  ìœ íš¨í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None

        except Exception as e:
            print(f"  âš ï¸  í‘œì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None

    def get_image_dimensions(self, image_data: bytes) -> Tuple[int, int]:
        """ì´ë¯¸ì§€ ë°ì´í„°ì—ì„œ ê°€ë¡œxì„¸ë¡œ í¬ê¸° ì¶”ì¶œ"""
        try:
            img = Image.open(BytesIO(image_data))
            return img.size  # (width, height)
        except Exception as e:
            print(f"  âš ï¸  ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ ì˜¤ë¥˜: {e}")
            return (0, 0)

    def search_naver_books(self, title: str, author: str = None) -> Optional[str]:
        """ë„¤ì´ë²„ ì±… ê²€ìƒ‰ì—ì„œ í‘œì§€ ì´ë¯¸ì§€ URL ê²€ìƒ‰"""
        try:
            # ë„¤ì´ë²„ ì±… ê²€ìƒ‰ (í¬ë¡¤ë§)
            from bs4 import BeautifulSoup

            search_query = f"{title} {author}" if author else title
            response = requests.get(
                'https://search.naver.com/search.naver',
                params={'where': 'book', 'sm': 'tab_jum', 'query': search_query},
                timeout=10,
                headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'}
            )

            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                # ì²« ë²ˆì§¸ ì±… í‘œì§€ ì´ë¯¸ì§€ ì°¾ê¸° (ì—…ë°ì´íŠ¸ëœ ì„ íƒì)
                img = soup.select_one('img.thumb')
                if img:
                    img_url = img.get('src') or img.get('data-src')
                    if img_url and img_url.startswith('http'):
                        # ê³ í•´ìƒë„ ë²„ì „ìœ¼ë¡œ ë³€ê²½ (type=w216 â†’ type=w600)
                        if 'type=w216' in img_url:
                            img_url = img_url.replace('type=w216', 'type=w600')
                        return img_url

            return None
        except Exception as e:
            print(f"  âš ï¸  ë„¤ì´ë²„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None


    def upgrade_low_resolution_cover(self, title: str, author: str, current_cover_path: Path) -> bool:
        """í•´ìƒë„ê°€ ë‚®ì€ í‘œì§€ë¥¼ í•œêµ­ ì„œì ì—ì„œ ë” ì¢‹ì€ ì´ë¯¸ì§€ë¡œ êµì²´"""
        try:
            # í˜„ì¬ ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
            with open(current_cover_path, 'rb') as f:
                current_data = f.read()

            width, height = self.get_image_dimensions(current_data)

            if width >= MIN_COVER_WIDTH:
                return False  # í•´ìƒë„ê°€ ì¶©ë¶„í•¨

            print(f"  ğŸ” í•´ìƒë„ê°€ ë‚®ìŒ ({width}x{height}), ë” ì¢‹ì€ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")

            # ë„¤ì´ë²„ ì±… ê²€ìƒ‰ì—ì„œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì°¾ê¸°
            bookstore_sources = [
                ('ë„¤ì´ë²„', self.search_naver_books),
            ]

            for store_name, search_func in bookstore_sources:
                img_url = search_func(title, author)

                if img_url:
                    # URL ìŠ¤í‚´ ìˆ˜ì • (//ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° https: ì¶”ê°€)
                    if img_url.startswith('//'):
                        img_url = 'https:' + img_url

                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    img_response = requests.get(img_url, timeout=10)

                    if img_response.status_code == 200 and len(img_response.content) > 1000:
                        new_width, new_height = self.get_image_dimensions(img_response.content)

                        # ë” í° ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
                        if new_width > width:
                            # íŒŒì¼ í˜•ì‹ ê°ì§€
                            if img_response.content[:8].startswith(b'\x89PNG'):
                                ext = '.png'
                            elif img_response.content[:3].startswith(b'\xff\xd8\xff'):
                                ext = '.jpg'
                            else:
                                ext = '.jpg'

                            # ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
                            current_cover_path.unlink()

                            # ìƒˆ íŒŒì¼ ì €ì¥
                            new_path = current_cover_path.parent / f"{title}{ext}"
                            with open(new_path, 'wb') as f:
                                f.write(img_response.content)

                            print(f"  âœ¨ {store_name}ì—ì„œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ: {new_width}x{new_height} ({len(img_response.content) // 1024}KB)")
                            return True

            print(f"  âš ï¸  ë” ì¢‹ì€ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í•¨")
            return False

        except Exception as e:
            print(f"  âš ï¸  ì´ë¯¸ì§€ ì—…ê·¸ë ˆì´ë“œ ì˜¤ë¥˜: {e}")
            return False

    def enrich_metadata(self, epub_filename: str) -> bool:
        """ë‹¨ì¼ ì±…ì˜ ë©”íƒ€ë°ì´í„° ë³´ì™„"""
        title = epub_filename.replace('.epub', '')
        metadata_path = METADATA_DIR / f"{title}.json"

        # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ì½ê¸°
        metadata = {}
        if metadata_path.exists():
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

        # ì´ë¯¸ ì™„ì „í•œ ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
        has_cover = metadata.get('cover') is not None
        has_description = metadata.get('description') is not None

        if has_cover and has_description:
            print(f"â­ï¸  {title[:50]}... - ì´ë¯¸ ì™„ì „í•œ ë©”íƒ€ë°ì´í„° ì¡´ì¬")
            self.skipped_count += 1
            return False

        print(f"ğŸ” {title[:50]}... ê²€ìƒ‰ ì¤‘...")

        # Google Booksì—ì„œ ê²€ìƒ‰
        book_info = self.search_google_books(title)

        if not book_info:
            print(f"  âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            self.failed_count += 1
            return False

        volume_info = book_info.get('volumeInfo', {})
        updated = False

        # ì„¤ëª… ë³´ì™„
        if not has_description and 'description' in volume_info:
            description = volume_info['description']
            metadata['description'] = description
            print(f"  âœ… ì„¤ëª… ì¶”ê°€: {description[:50]}...")
            updated = True

        # í‘œì§€ ë³´ì™„
        if not has_cover and 'imageLinks' in volume_info:
            image_links = volume_info['imageLinks']
            # thumbnail ë˜ëŠ” smallThumbnail ì‚¬ìš©
            image_url = image_links.get('thumbnail') or image_links.get('smallThumbnail')

            if image_url:
                cover_filename = self.download_cover_image(image_url, epub_filename)

                if cover_filename:
                    metadata['cover'] = cover_filename
                    print(f"  âœ… í‘œì§€ ë‹¤ìš´ë¡œë“œ: {cover_filename}")
                    updated = True

                    # í•´ìƒë„ ì²´í¬ ë° ì—…ê·¸ë ˆì´ë“œ
                    cover_path = COVERS_DIR / cover_filename
                    author = metadata.get('author', '')
                    if self.upgrade_low_resolution_cover(title, author, cover_path):
                        # íŒŒì¼ëª…ì´ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                        new_cover_filename = None
                        for ext in ['.jpg', '.png']:
                            possible_path = COVERS_DIR / f"{title}{ext}"
                            if possible_path.exists():
                                new_cover_filename = f"{title}{ext}"
                                break
                        if new_cover_filename and new_cover_filename != cover_filename:
                            metadata['cover'] = new_cover_filename

        # ê¸°íƒ€ ë©”íƒ€ë°ì´í„° ë³´ì™„
        if 'authors' in volume_info and not metadata.get('author'):
            metadata['author'] = ', '.join(volume_info['authors'])
            print(f"  âœ… ì €ì ì¶”ê°€: {metadata['author']}")
            updated = True

        if 'publishedDate' in volume_info and not metadata.get('year'):
            # YYYY-MM-DD í˜•ì‹ì—ì„œ ì—°ë„ë§Œ ì¶”ì¶œ
            year = volume_info['publishedDate'].split('-')[0]
            metadata['year'] = year
            print(f"  âœ… ì¶œíŒë…„ë„ ì¶”ê°€: {year}")
            updated = True

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        if updated:
            METADATA_DIR.mkdir(parents=True, exist_ok=True)

            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

            self.updated_count += 1
            print(f"  ğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            return True
        else:
            print(f"  âš ï¸  ë³´ì™„í•  ì •ë³´ ì—†ìŒ")
            self.failed_count += 1
            return False

    def run(self):
        """ëª¨ë“  EPUB íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° ë³´ì™„"""
        print("=" * 60)
        print("ğŸ“š Dream Library ë©”íƒ€ë°ì´í„° ë³´ì™„ ì‹œì‘")
        print("=" * 60)

        # covers ë””ë ‰í† ë¦¬ ìƒì„±
        COVERS_DIR.mkdir(parents=True, exist_ok=True)

        # EPUB íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        epub_files = list(BOOKS_DIR.glob("*.epub"))

        if not epub_files:
            print("âŒ EPUB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\nì´ {len(epub_files)}ê°œì˜ ì±…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n")

        for i, epub_path in enumerate(epub_files, 1):
            print(f"\n[{i}/{len(epub_files)}] ", end="")
            self.enrich_metadata(epub_path.name)

            # API í˜¸ì¶œ ì œí•œ ê³ ë ¤ (1ì´ˆ ëŒ€ê¸°)
            if i < len(epub_files):
                time.sleep(1)

        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼")
        print("=" * 60)
        print(f"âœ… ì—…ë°ì´íŠ¸ë¨: {self.updated_count}ê°œ")
        print(f"â­ï¸  ìŠ¤í‚µë¨: {self.skipped_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {self.failed_count}ê°œ")
        print("=" * 60)

if __name__ == "__main__":
    enricher = MetadataEnricher()
    enricher.run()
